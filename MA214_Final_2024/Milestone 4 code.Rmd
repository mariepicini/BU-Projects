---
title: "Milestone 4 code"
output: html_document
date: '2024-11-28'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# import dataset
library(readr)
Movies_new <- read_csv("Movies.csv")

# subtract data
moviedf = subset(Movies_new, select = -c(movie_id, status,imdb_id, original_title, overview, original_language, spoken_languages, production_countries, production_companies, genres, title))

moviedf$release_date <- as.numeric(format(as.Date(moviedf$release_date, format="%m/%d/%Y"),"%Y"))
moviedf <- moviedf[!( moviedf$adult == TRUE), ]

moviedf <- subset(moviedf, select = -c(adult))
colnames(moviedf)
# clean data by removing all the rows that contained zeros
library(dplyr)
cleaned_data <- moviedf[rowSums(select_if(moviedf, is.numeric) == 0, na.rm = TRUE) == 0, ]
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}

library(corrplot)

## Budget:
model <- lm(vote_average ~ budget, data = cleaned_data)
plot(cleaned_data$budget, cleaned_data$vote_average, pch = 16, main = "Simple Linear Regression", xlab = "Budget", ylab = "Vote Average")
residuals <- residuals(model)
plot(cleaned_data$budget, residuals, pch = 16, main = "Residuals vs Budget", xlab = "Budget", ylab = "Residuals")

# transformation1 (poly)
model_trans1 <- lm(vote_average ~ poly(budget, 3), data = cleaned_data)
plot(cleaned_data$budget, residuals(model_trans1), main = "Residuals vs Budget (Quadratic Model)", ylab = "Residuals", xlab = "Budget")

# transformation2(logX)
cleaned_data$log_budget <- log(cleaned_data$budget + 1)
model_trans2 <- lm(vote_average ~ log_budget, data = cleaned_data)
plot(cleaned_data$log_budget, residuals(model_trans2), main = "Residuals vs Log(Budget)", ylab = "Residuals", xlab = "Log(Budget)")

# combined transformation
model_poly <- lm(vote_average ~ poly(log_budget, 3), data = cleaned_data)
plot(cleaned_data$log_budget, residuals(model_poly), 
     main = "Residuals vs Log(Budget) (Cubic Model)", 
     ylab = "Residuals", xlab = "Log(Budget)")
abline(h = 0, col = "red")

# full model
model_full <- lm(vote_average ~ budget + vote_count + popularity + release_date + revenue , data = cleaned_data)
plot(model_full)

# transform full model by adding log
#cleaned_data$log_budget <- log(cleaned_data$budget + 1)
cleaned_data$log_revenue <- log(cleaned_data$revenue + 1)
cleaned_data$log_vote_count <- log(cleaned_data$vote_count + 1)

model_transformed <- lm(vote_average ~ log_budget + log_vote_count + popularity + release_date + log_revenue, data = cleaned_data)
plot(model_transformed, which = 1)

# transform full model by doing poly
model_cubic <- lm(vote_average ~ poly(budget, 3) + vote_count + poly(popularity, 3) + release_date + revenue, data = cleaned_data)
plot(model_cubic, which = 1) 

# add interaction term
model_interaction <- lm(vote_average ~ budget * popularity + vote_count + release_date + revenue, data = cleaned_data)
plot(model_interaction, which = 1)

# transform full model by log y
cleaned_data$log_vote_average <- log(cleaned_data$vote_average + 1)
model_log <- lm(log_vote_average ~ poly(budget, 3) + vote_count + poly(popularity, 3) + release_date + revenue, 
                data = cleaned_data)
plot(model_log, which = 1) 

# combine interaction, log and poly
model_combine <- lm(log_vote_average ~ poly(budget, 3) + vote_count + poly(popularity, 3) + release_date + revenue + budget * popularity, 
                data = cleaned_data)
plot(model_combine, which = 1) 

anova(model_full)
summary(model_full)

# check Multicollinearity
quantitative_vars <- cleaned_data[, c("vote_average","budget", "vote_count", "popularity", "release_date", "revenue")]
cor_matrix <- cor(quantitative_vars, use = "pairwise.complete.obs")
corrplot(cor_matrix, method = "color", type = "upper", 
          tl.col = "black", tl.cex = 0.8, addCoef.col = "black")

## try remove vote_count --> adjusted r square decreased
model_try <- lm(vote_average ~ budget + popularity + release_date + revenue , data = cleaned_data)
summary(model_try)
## try remove budget--> adjusted r square decreased 
model_try2 <- lm(vote_average ~ vote_count + popularity + release_date + revenue , data = cleaned_data)
summary(model_try2)
## try remove revenue--> adjusted r does not change much --> use this
model_try3 <- lm(vote_average ~ vote_count + popularity + release_date + budget , data = cleaned_data)
summary(model_try3)

# full model after checking multicollinearity
final_full_model <- lm(vote_average ~ vote_count + popularity + release_date + budget , data = cleaned_data)

```

## Including Plots

You can also embed plots, for example:

```{r pressure}
#install.packages('glmnet')
#install.packages("olsrr")
library(olsrr)
library(glmnet)

ols_step_forward_p(final_full_model, data=cleaned_data, p_enter = .25, p_remove = .1, details = TRUE)
ols_step_backward_p(final_full_model, data = cleaned_data, p_enter = .25, p_remove = .1, details=TRUE)

cleaned_data <- na.omit(cleaned_data)
selected_vars <- c('vote_count', 'revenue', 'budget', 'popularity', 'release_date')
y <- cleaned_data$vote_average
x <- data.matrix(cleaned_data[, selected_vars])

cv_model <- cv.glmnet(x, y, alpha = 1)
best_lambda <- cv_model$lambda.min

best_model <- glmnet(x, y, alpha = 1, lambda = best_lambda)
coef(best_model)

# Scale the selected variables
scaled_data <- cleaned_data

# Scale specific columns (you can exclude 'release_date' if you don't want to scale it)
scaled_data$vote_count <- scale(scaled_data$vote_count)
scaled_data$revenue <- scale(scaled_data$revenue)
scaled_data$budget <- scale(scaled_data$budget)
scaled_data$popularity <- scale(scaled_data$popularity)

# Define the response variable
y <- scaled_data$vote_average

# Define the predictor matrix (with scaled values)
x <- data.matrix(scaled_data[, selected_vars])

# Fit the Lasso model again using scaled data
cv_model <- cv.glmnet(x, y, alpha = 1)

# Find the optimal lambda value
best_lambda <- cv_model$lambda.min

# Fit the final model
best_model <- glmnet(x, y, alpha = 1, lambda = best_lambda)

# Display the coefficients of the final model
coef(best_model)



```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
